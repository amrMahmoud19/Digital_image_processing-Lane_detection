{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6d4eda35",
   "metadata": {},
   "source": [
    "# Phase 2 - YOLO object detection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e8c5884",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0bbd116b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import time\n",
    "import cv2 \n",
    "import os\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "COLOR = (170,205,102)\n",
    "COLOR_TEXT = (255,0,255)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "106ac66d",
   "metadata": {},
   "source": [
    "## Passing weights and configuration file to neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ada302d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# weights_path = os.path.join(\"Downloads\\yolo\", \"yolov3.weights\")\n",
    "# config_path = os.path.join(\"Downloads\\yolo\", \"yolov3.cfg\")\n",
    "weights_path = \"yolov3.weights\"\n",
    "config_path = \"yolov3.cfg\"\n",
    "label_path = \"coco.names\"\n",
    "labels = open(label_path).read().strip().split(\"\\n\") # strip btremove el spaces ely mwgoda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b8089314",
   "metadata": {},
   "outputs": [],
   "source": [
    "net = cv2.dnn.readNetFromDarknet(config_path, weights_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9c33f8f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "names = net.getLayerNames()\n",
    "# extracting the layer names\n",
    "layer_names = [ names[ i[0]-1 ] for i in net.getUnconnectedOutLayers() ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7ee9f98a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect(img):\n",
    "   \n",
    "    \n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    (H, W) = img.shape[:2]\n",
    "\n",
    "    blob = cv2.dnn.blobFromImage(img, 1/255.0, (416,416), crop=False, swapRB = False) # swapRB = False lw ana swapthom fo2 w ana bimport\n",
    "    net.setInput(blob)\n",
    "    \n",
    "    names = net.getLayerNames()\n",
    "    # extracting the layer names\n",
    "    layer_names = [ names[ i[0]-1 ] for i in net.getUnconnectedOutLayers() ]\n",
    "\n",
    "    layers_output = net.forward(layer_names) # performing a forward pass through the layers\n",
    "\n",
    "    boxes = []\n",
    "    classIDs = []\n",
    "    confidences = []\n",
    "\n",
    "    for output in layers_output:\n",
    "       \n",
    "        for detection in output:\n",
    "\n",
    "            scores = detection[5:]\n",
    "            classID = np.argmax(scores)\n",
    "\n",
    "            confidence = scores[classID]\n",
    "\n",
    "            if (confidence > 0.85):\n",
    "                box = detection[:4]*np.array([W, H, W, H]) # leh 3mlna multiply????\n",
    "                bx, by, bw, bh = box.astype(\"int\")\n",
    "\n",
    "                # 3ayzeen el upperleft corners msh el centers 3shan kdh 3mlna el subtraction dh\n",
    "                x = int(bx - bw/2)\n",
    "                y = int(by - bh/2)\n",
    "\n",
    "                boxes.append([x, y, int(bw), int(bh)])\n",
    "                confidences.append(float(confidence))\n",
    "                classIDs.append(classID)\n",
    "    idxs = np.asarray(cv2.dnn.NMSBoxes(boxes, confidences, 0.65,0.7)) # lazem confidences tb2a float\n",
    "\n",
    "    for i in idxs.flatten():\n",
    "        (x, y, w, h) = [boxes[i][0], boxes[i][1], boxes[i][2], boxes[i][3]]\n",
    "\n",
    "        # drawing the boxes\n",
    "        img = cv2.rectangle(img, (x,y), (x+w,y+h), COLOR, 2 )\n",
    "\n",
    "        # Putting name of detected object and accuracy of detection\n",
    "        cv2.putText(img,\"{} : {:.3f}\".format(labels[classIDs[i]], confidences[i]), (x,y-5), cv2.FONT_HERSHEY_SIMPLEX,0.5, COLOR_TEXT,2)\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "93206759",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_name = \"project_video\"\n",
    "isVideo = False\n",
    "path = r\"C:\\Users\\amrma\\Downloads\\test9.jpg\"\n",
    "cap = cv2.VideoCapture(path)\n",
    "\n",
    "\n",
    "output_name = input_name + '_output'\n",
    "size = (1280 , 720)\n",
    "\n",
    "fourcc = cv2.VideoWriter_fourcc(*'DIVX')\n",
    "out = cv2.VideoWriter(output_name +'.mp4', fourcc, 25, size)\n",
    "\n",
    "while(cap.isOpened()):\n",
    "    ret, frame = cap.read()\n",
    "    if ret==True:\n",
    "        image = detect(frame)\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        if isVideo:\n",
    "            \n",
    "            out.write(image)\n",
    "    #         cv2.imshow('frame',image)\n",
    "\n",
    "            if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "                break\n",
    "        else:\n",
    "            cv2.imshow('Modified Image', image)\n",
    "            cv2.waitKey(0)\n",
    "            break\n",
    "        \n",
    "    \n",
    "    else:\n",
    "        break\n",
    "cap.release()\n",
    "\n",
    "out.release()\n",
    "\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
