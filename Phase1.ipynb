{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a6220b23",
   "metadata": {},
   "source": [
    "# Team members:\n",
    "## Amr Mohsen Mohamed - 1801938\n",
    "## Amr Mahmoud Ali Mahmoud - 1802099"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cb0ce652",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ef8bfd3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def PerspectiveTransform(src,dst):\n",
    "    mat = cv2.getPerspectiveTransform(src,dst)\n",
    "    mat_inv = cv2.getPerspectiveTransform(dst,src)\n",
    "    return mat,mat_inv\n",
    "\n",
    "def warpPerspective(img, mat, size):\n",
    "    return cv2.warpPerspective(img, mat,size)\n",
    "\n",
    "#function for converting the image to hls mode then return s as it is the one we are intrested in studying\n",
    "def trans2hls(image):\n",
    "    img_hls = cv2.cvtColor(image, cv2.COLOR_BGR2HLS)\n",
    "    (h,l,s) = cv2.split(img_hls)\n",
    "    #MODIFIED\n",
    "    return h,l,s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dee4722d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#images must have the same dimension\n",
    "#takes a list of images and produces an image of them concantenated in a 2D array-like shape\n",
    "#need to take care of colored images \n",
    "def debug_mode(images , resize_factor):\n",
    "    x_dim = int(images[0].shape[1] / resize_factor)\n",
    "    y_dim = int(images[0].shape[0] / resize_factor)\n",
    "    n_h_images = len(images)\n",
    "    \n",
    "    #if there are odd number of images add a dummy black image to the end of the list\n",
    "    if (n_h_images % 2 )!= 0:\n",
    "        images.append(np.zeros_like(images[n_h_images - 1]))    \n",
    "        \n",
    "    i = 0\n",
    "    horiz_conc_image = list()\n",
    "    while i < n_h_images:\n",
    "        #if gray scale convert to RGB\n",
    "        if len(images[i].shape) == 2:\n",
    "            images[i] = cv2.resize(cv2.cvtColor(images[i],cv2.COLOR_GRAY2BGR), (x_dim , y_dim), interpolation= cv2.INTER_LINEAR)\n",
    "        else:\n",
    "            images[i] = cv2.resize(images[i], (x_dim , y_dim), interpolation= cv2.INTER_LINEAR)\n",
    "        if len(images[i+1].shape) == 2:\n",
    "            images[i + 1] = cv2.resize(cv2.cvtColor(images[i+1],cv2.COLOR_GRAY2BGR), (x_dim , y_dim), interpolation= cv2.INTER_LINEAR)\n",
    "        else:\n",
    "            images[i + 1] = cv2.resize(images[i+1], (x_dim , y_dim), interpolation= cv2.INTER_LINEAR)\n",
    "        #concatenate each two successive images horizontally\n",
    "        horiz_conc_image.append(cv2.hconcat([images[i] , images[i+1]]))\n",
    "        i += 2\n",
    "    #concatenate the resulting horizontally conc. images vertically\n",
    "    debug_image = cv2.vconcat(horiz_conc_image)\n",
    "\n",
    "    return debug_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "866a6b4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_edges(image , s_thresh , l_thresh , shad_thresh= (50,155)):\n",
    "    (h,l,s) = trans2hls(image)\n",
    "    \n",
    "    canny_l = cv2.Canny(l,l_thresh[0],l_thresh[1])\n",
    "    ext_shadow = np.zeros_like(h)\n",
    "    ext_shadow[(l < shad_thresh[0]) & (s > shad_thresh[1])] = 1\n",
    "    \n",
    "    \n",
    "#     canny_l[canny_l == 255] = 1\n",
    "    s_binary = np.zeros_like(s)\n",
    "    s_binary[(s >= s_thresh[0]) & (s <= s_thresh[1])] = 255\n",
    "    \n",
    "    combined_binary = np.zeros_like(canny_l)\n",
    "    combined_binary[(s_binary == 255) | (canny_l == 255)] = 255\n",
    "    combined_binary[ext_shadow == 1] = 0\n",
    "    return combined_binary,s_binary,canny_l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b0aaa7e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sliding_window(img,dst_colored, window_size , right_poly_old, init , frame_discard):\n",
    "    #window_size = (hight , width)\n",
    "    #shape= (720 * 1280)\n",
    "    #convert to colored img to draw colored line and windows on top of it\n",
    "    \n",
    "    out_img = cv2.cvtColor(img , cv2.COLOR_GRAY2RGB)\n",
    "    \n",
    "    nwindows = int(img.shape[0] / window_size[0])\n",
    "   \n",
    "    # find peaks of left and right lanes\n",
    "    histogram = np.sum(img, axis=0)\n",
    "    midpoint = int(histogram.shape[0]//2)\n",
    "    start_left_x= np.argmax(histogram[:midpoint - 115])\n",
    "    start_right_x = np.argmax(histogram[midpoint + 100:]) + midpoint + 100\n",
    "    \n",
    "    #get positions of white pixels in original img\n",
    "    white_pixels = img.nonzero()\n",
    "    white_x = np.array(white_pixels[1])\n",
    "    white_y = np.array(white_pixels[0])\n",
    "\n",
    "    \n",
    "    # the left and right lane indices that we are going to find\n",
    "    left_lane_indices = []\n",
    "    right_lane_indices = []\n",
    "    \n",
    "    for window in range(nwindows):\n",
    "        \n",
    "        # find the boundary of each window\n",
    "        win_bot = img.shape[0] - (window+1)*window_size[0]\n",
    "        win_top = img.shape[0] - window*window_size[0]\n",
    "        left_lane_lbound = start_left_x - window_size[1]\n",
    "        left_lane_rbound = start_left_x + window_size[1]\n",
    "        right_lane_lbound = start_right_x - window_size[1]\n",
    "        right_lane_rbound = start_right_x + window_size[1]\n",
    "        \n",
    "        #draw the windows in red\n",
    "        cv2.rectangle(dst_colored,(left_lane_lbound,win_bot),(left_lane_rbound,win_top),(255,0,0), 3) \n",
    "        cv2.rectangle(dst_colored,(right_lane_lbound,win_bot),(right_lane_rbound,win_top),(255,0,0), 3) \n",
    "        \n",
    "        #locate the white pixels that lie within current window \n",
    "        good_left_inds = ((white_y >= win_bot) & (white_y < win_top) & \n",
    "        (white_x >= left_lane_lbound) &  (white_x < left_lane_rbound)).nonzero()[0]\n",
    "        good_right_inds = ((white_y >= win_bot) & (white_y < win_top) & \n",
    "        (white_x >= right_lane_lbound) &  (white_x < right_lane_rbound)).nonzero()[0]\n",
    "        \n",
    "        left_lane_indices.append(good_left_inds)\n",
    "        right_lane_indices.append(good_right_inds)\n",
    "        \n",
    "        #if the window contain black pixels don't shift it\n",
    "        if len(good_left_inds) > 65:\n",
    "            start_left_x = int(np.mean(white_x[good_left_inds]))\n",
    "        if len(good_right_inds) > 65:        \n",
    "            start_right_x = int(np.mean(white_x[good_right_inds]))\n",
    "\n",
    "            \n",
    "    left_lane_indices = np.concatenate(left_lane_indices)\n",
    "    right_lane_indices = np.concatenate(right_lane_indices)\n",
    "\n",
    "    \n",
    "    leftx = white_x[left_lane_indices]\n",
    "    lefty = white_y[left_lane_indices] \n",
    "    rightx = white_x[right_lane_indices]\n",
    "    righty = white_y[right_lane_indices] \n",
    "\n",
    "    #fit a 2nd degree curve to the white pixels positions we found\n",
    "    left_fit = np.polyfit(lefty, leftx, 2)\n",
    "    right_fit = np.polyfit(righty, rightx, 2)\n",
    "    \n",
    "    \n",
    "    #predict the current position\n",
    "    ploty = np.linspace(0, 719, 720 )\n",
    "    left_fitx = np.polyval(left_fit , ploty)\n",
    "    right_fitx = np.polyval(right_fit , ploty)\n",
    "    \n",
    "    left_poly = np.asarray(tuple(zip(left_fitx,ploty)) ,np.int32)\n",
    "    right_poly = np.asarray(tuple(zip(right_fitx,ploty)),np.int32)\n",
    "    if init == True:\n",
    "        if abs(right_poly_old[30][0] - right_poly[30][0]) > frame_discard:\n",
    "            right_poly = right_poly_old\n",
    "    \n",
    "    #draw the lanes \n",
    "    cv2.polylines(dst_colored , [left_poly] , isClosed = False , color=(0,255,0) , thickness=50)\n",
    "    cv2.polylines(dst_colored , [right_poly], isClosed = False , color=(0,0,255), thickness= 50)\n",
    "    \n",
    "    return dst_colored, right_poly,left_fitx , right_fitx,ploty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5c2cb3a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_off_dist(frame, right_lane_pts, left_lane_pts):                     #Calculating distance off center\n",
    "        \n",
    "        centre_car = (frame.shape[1]//2, 720)                                #determining center of car from original view\n",
    "        \n",
    "        #transforming centre coordinates into bird-eye view\n",
    "        px = (M[0][0]*centre_car[0] + M[0][1]*centre_car[1] + M[0][2]) / ((M[2][0]*centre_car[0] + M[2][1]*centre_car[1] + M[2][2]))\n",
    "        py = (M[1][0]*centre_car[0] + M[1][1]*centre_car[1] + M[1][2]) / ((M[2][0]*centre_car[0] + M[2][1]*centre_car[1] + M[2][2]))\n",
    "        \n",
    "        centre_car = (int(px), int(py))\n",
    "        \n",
    "        #getting left and right lane points indicating width of lane which is 3 meters\n",
    "        right_lane_x = right_lane_pts[0]\n",
    "        \n",
    "        left_lane_x  = left_lane_pts[0]\n",
    "        \n",
    "        dst_px = abs(right_lane_x - left_lane_x)    #width of lane in pixels\n",
    "        dst_real = 300                              #distance of lane in cm\n",
    "        scale = dst_real/dst_px                     #scaling factor for transfroming distance from pixels to cm\n",
    "        \n",
    "        centre_lane = (dst_px//2 + left_lane_x)\n",
    "        dst_off_px = abs(centre_lane - centre_car[0])  #distance off centre in pixels\n",
    "        \n",
    "        dst_off = dst_off_px*scale               #distance off centre in meters\n",
    "        dst_off = round(dst_off/100,2)\n",
    "        \n",
    "        return dst_off"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7fd607b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "93206759",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_name = \"project_video\"\n",
    "path = r\"C:\\Users\\amrmo\\Documents\\Digital_image_processing-Lane_detection\\Project_data\\\\\"+ input_name +\".mp4\"\n",
    "cap = cv2.VideoCapture(path)\n",
    "#Project_video Thresholds\n",
    "# s_thresh = (160, 255) \n",
    "# l_thresh = (150 , 255)\n",
    "\n",
    "challenge = False\n",
    "\n",
    "#thresholding of s channel\n",
    "#opt = 75\n",
    "s_thresh = (75, 255) \n",
    "#canny\n",
    "l_thresh = (140 , 255)\n",
    "#shadow threshold\n",
    "#(lightness , sat)\n",
    "#inc l dec s\n",
    "#200,100\n",
    "shad_thresh = (150,100)\n",
    "\n",
    "debug = 1\n",
    "debug_resize = 3\n",
    "ny_pipeline = 3\n",
    "output_name = input_name + '_output'\n",
    "size = (1280 , 720)\n",
    "if debug == 1:\n",
    "    pipeline = []\n",
    "    output_name += '_debug'\n",
    "    size = ((1280 // debug_resize) * 2 , (720 // debug_resize) * ny_pipeline)\n",
    "\n",
    "\n",
    "if challenge == False:\n",
    "    #for project video\n",
    "    input_top_left = [550,468]\n",
    "    input_top_right = [742,468]\n",
    "    input_bottom_right = [1280,720]\n",
    "    input_bottom_left = [128,720]\n",
    "else:\n",
    "    #for challenge video\n",
    "    input_top_left = [580,500]\n",
    "    input_top_right = [760,500]\n",
    "    input_bottom_right = [1180,720]\n",
    "    input_bottom_left = [170,720]\n",
    "\n",
    "src_pt = np.float32([input_bottom_left,input_top_left,input_top_right,input_bottom_right])\n",
    "dst_pt = np.float32([[0,720],[0,0],[1280,0],[1280,720]])\n",
    "init = False\n",
    "right_poly_old = np.zeros((720 , 2 , 2) , np.int32)\n",
    "\n",
    "fourcc = cv2.VideoWriter_fourcc(*'DIVX')\n",
    "out = cv2.VideoWriter(output_name +'.mp4', fourcc, 25, size)\n",
    "\n",
    "while(cap.isOpened()):\n",
    "    ret, frame = cap.read()\n",
    "    if ret==True:\n",
    "        \n",
    "        (combined_binary,l,s) = detect_edges(frame , s_thresh , l_thresh,shad_thresh)\n",
    "#         kernel_op = np.asarray([[0 , 1, 0],\n",
    "#                                [0, 1 , 0],\n",
    "#                                [0 , 1, 0]] , np.uint8)\n",
    "        kernel_co = np.ones((3,3) , np.uint8)\n",
    "#         combined_binary = cv2.morphologyEx(combined_binary, cv2.MORPH_OPEN ,kernel_op)\n",
    "        combined_binary = cv2.dilate(combined_binary,kernel_co)\n",
    "        M,Minv = PerspectiveTransform(src_pt , dst_pt)\n",
    "        dst = warpPerspective(combined_binary ,M , (1280 , 720))\n",
    "                \n",
    "#         dst_colored = perspective_warp(frame ,src=input_points , dst=p2)\n",
    "        dst_colored = warpPerspective(frame ,M , (1280 , 720))\n",
    "        out_img,right_poly_new ,left_fit , right_fit,ploty= sliding_window(dst , dst_colored, (72 , 128),right_poly_old,init,150)\n",
    "        right_poly_old = right_poly_new\n",
    "        \n",
    "        left = np.array([np.transpose(np.vstack([left_fit, ploty]))])\n",
    "        right = np.array([np.flipud(np.transpose(np.vstack([right_fit, ploty])))])\n",
    "        points = np.hstack((left, right))\n",
    "        \n",
    "        \n",
    "        init = True\n",
    "        cv2.fillPoly(out_img,np.int_(points),color= (255,0,0))\n",
    "        \n",
    "        re_bird = warpPerspective(out_img , Minv , (1280,720) )\n",
    "        \n",
    "        #printing the off-centre distance on video frame\n",
    "        dst_off = calc_off_dist(frame ,right_poly_new[350], left_poly[350])\n",
    "        re_bird = cv2.putText(img=re_bird, text='The car is '+str(dst_off)+' off centre' , org=(0,100), fontFace=cv2.FONT_HERSHEY_TRIPLEX, fontScale=2, color=(255, 255, 255),thickness=3)\n",
    "        \n",
    "        image = np.zeros_like(frame)\n",
    "        cv2.addWeighted(frame, 0.5, re_bird, 0.5,0, image)\n",
    "        \n",
    "        if debug == 1:\n",
    "            pipeline.append(l)\n",
    "            pipeline.append(s)\n",
    "            pipeline.append(combined_binary)\n",
    "            pipeline.append(dst)\n",
    "            pipeline.append(dst_colored)\n",
    "            pipeline.append(image)\n",
    "            image = debug_mode(pipeline , debug_resize)\n",
    "            pipeline.clear()\n",
    "        \n",
    "        out.write(image)\n",
    "        cv2.imshow('frame',image)\n",
    "        \n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "    else:\n",
    "        break\n",
    "cap.release()\n",
    "\n",
    "out.release()\n",
    "\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
