{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cb0ce652",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "#constants\n",
    "LANE_WIDTH = 340\n",
    "challenge = 'challenge_video.mp4'\n",
    "normal = 'project_video.mp4'\n",
    "cap = cv2.VideoCapture(\"project_data\\\\\"+ normal )\n",
    "# debug = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ef8bfd3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def PerspectiveTransform(src,dst):\n",
    "    mat = cv2.getPerspectiveTransform(src,dst)\n",
    "    mat_inv = cv2.getPerspectiveTransform(dst,src)\n",
    "    return mat,mat_inv\n",
    "\n",
    "def warpPerspective(img, mat, size):\n",
    "    return cv2.warpPerspective(img, mat,size, cv2.INTER_LINEAR)\n",
    "\n",
    "#function for converting the image to hls mode then return s as it is the one we are intrested in studying\n",
    "def trans2hls(image):\n",
    "    img_hls = cv2.cvtColor(image, cv2.COLOR_BGR2HLS)\n",
    "    (h,l,s) = cv2.split(img_hls)\n",
    "    #MODIFIED\n",
    "    return (l,s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dee4722d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#images must have the same dimension\n",
    "#takes a list of images and produces an image of them concantenated in a 2D array-like shape\n",
    "#need to take care of colored images \n",
    "def debug_mode(images , resize_factor):\n",
    "    x_dim = int(images[0].shape[1] / resize_factor)\n",
    "    y_dim = int(images[0].shape[0] / resize_factor)\n",
    "    n_h_images = len(images)\n",
    "    \n",
    "    #if there are odd number of images add a dummy black image to the end of the list\n",
    "    if (n_h_images % 2 )!= 0:\n",
    "        images.append(np.zeros_like(images[n_h_images - 1]))    \n",
    "        \n",
    "    i = 0\n",
    "    horiz_conc_image = list()\n",
    "    while i < n_h_images:\n",
    "        #if gray scale convert to RGB\n",
    "        if len(images[i].shape) == 2:\n",
    "            images[i] = cv2.resize(cv2.cvtColor(images[i],cv2.COLOR_GRAY2BGR), (x_dim , y_dim), interpolation= cv2.INTER_LINEAR)\n",
    "        else:\n",
    "            images[i] = cv2.resize(images[i], (x_dim , y_dim), interpolation= cv2.INTER_LINEAR)\n",
    "        if len(images[i+1].shape) == 2:\n",
    "            images[i + 1] = cv2.resize(cv2.cvtColor(images[i+1],cv2.COLOR_GRAY2BGR), (x_dim , y_dim), interpolation= cv2.INTER_LINEAR)\n",
    "        else:\n",
    "            images[i + 1] = cv2.resize(images[i+1], (x_dim , y_dim), interpolation= cv2.INTER_LINEAR)\n",
    "        #concatenate each two successive images horizontally\n",
    "        horiz_conc_image.append(cv2.hconcat([images[i] , images[i+1]]))\n",
    "        i += 2\n",
    "    #concatenate the resulting horizontally conc. images vertically\n",
    "    debug_image = cv2.vconcat(horiz_conc_image)\n",
    "\n",
    "    return debug_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "866a6b4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_edges(image , s_thresh , l_thresh , shad_thresh= (50,155)):\n",
    "    hls_image = color_to_hls(image)\n",
    "    (h,l,s) = cv.split(hls_image)\n",
    "    \n",
    "    canny_l = cv.Canny(l,l_thresh[0],l_thresh[1])\n",
    "    ext_shadow = np.zeros_like(h)\n",
    "    ext_shadow[(l < shad_thresh[0]) & (s > shad_thresh[1])] = 1\n",
    "    \n",
    "    \n",
    "#     canny_l[canny_l == 255] = 1\n",
    "    s_binary = np.zeros_like(s)\n",
    "    s_binary[(s >= s_thresh[0]) & (s <= s_thresh[1])] = 255\n",
    "    \n",
    "    combined_binary = np.zeros_like(canny_l)\n",
    "    combined_binary[(s_binary == 255) | (canny_l == 255)] = 255\n",
    "    combined_binary[ext_shadow == 1] = 0\n",
    "    return combined_binary,s_binary,cany_l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b0aaa7e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def detectLane(frame, src_pts, dst_pts, size, kernel_op_size, kernel_cl_size , debug):\n",
    "    #colors for drawing line\n",
    "    red = (255 , 0 ,0)\n",
    "    green = (0 ,255,0)\n",
    "    \n",
    "    #bounds init\n",
    "    left = 0\n",
    "    bound_bottom_left = (0,0)\n",
    "    bound_bottom_right = (0,0)\n",
    "    pipeline = list()\n",
    "    \n",
    "    sat = trans2hls(frame)[1]\n",
    "    l = trans2hls(frame)[0]\n",
    "#     pipeline.append(sat)\n",
    "    \n",
    "    #MODIFIED\n",
    "    canny_s = cv2.Canny(sat,50,150)\n",
    "    canny_l = cv2.Canny(l,50,150)\n",
    "    pipeline.append(canny_s)\n",
    "    pipeline.append(canny_l)\n",
    "    \n",
    "    \n",
    "\n",
    "    #pre-processing the edge extracted image\n",
    "    #performing opening operation to remove extra noise\n",
    "    open_canny = cv2.morphologyEx(canny_l, cv2.MORPH_OPEN,np.ones(kernel_op_size, np.uint8))\n",
    "    pipeline.append(open_canny)\n",
    "    \n",
    "    #performing closing operation to thicken lane lines\n",
    "    close_canny = cv2.morphologyEx(open_canny, cv2.MORPH_CLOSE,np.ones(kernel_cl_size, np.uint8))\n",
    "    pipeline.append(close_canny)\n",
    "    \n",
    "    #performing perspective transform\n",
    "    mat, mat_inv = PerspectiveTransform(src_pts,dst_pts)\n",
    "    bird_view_gray = warpPerspective(close_canny,mat,size)\n",
    "    bird_view = warpPerspective(frame,mat,size)\n",
    "#     pipeline.append(bird_view)\n",
    "    #retrans = warpPerspective(bird_view_gray, mat_inv, size)\n",
    "    \n",
    "    #detecting lane lines\n",
    "    lines = cv2.HoughLinesP(bird_view_gray,1, np.pi/180,50,minLineLength=400, maxLineGap=60 )\n",
    "    \n",
    "    #line[0] returns x,y reversed where x is horizontal axis and y is the vertical axis\n",
    "    i=0\n",
    "    for line in lines:\n",
    "        x1,y1,x2,y2 = line[0]\n",
    "        if(x1>350): #in case the second lane line was on the right side\n",
    "            cv2.line(bird_view,(x1,y1),(x2,y2),red,2)\n",
    "            if(x1+LANE_WIDTH < 900):\n",
    "                cv2.line(bird_view,(x1+LANE_WIDTH,y1),(x2+LANE_WIDTH,y2),red,2)\n",
    "                x3 = x1+LANE_WIDTH\n",
    "                x4 = x2+LANE_WIDTH\n",
    "            if(x1-LANE_WIDTH > 300): #in case the second lane line was on the left\n",
    "                left = 1\n",
    "                cv2.line(bird_view,(x1-LANE_WIDTH,y1),(x2-LANE_WIDTH,y2),red,2)\n",
    "                x3 = x1-LANE_WIDTH\n",
    "                x4 = x2-LANE_WIDTH\n",
    "\n",
    "            #340 is fixed which represents the lane width\n",
    "            if(i<=4):\n",
    "                #getting the boundary of lines to draw the contour(boundary)\n",
    "    ###### momken a7sen fe deh eny a3mlha b minimum w maximum x1 w x2\n",
    "                bound_top_left= (x1,y1)\n",
    "                bound_top_right= (x3,y1)\n",
    "            \n",
    "            if(y2 > bound_bottom_left[1]):\n",
    "            \n",
    "                bound_bottom_left = (x2,y2)\n",
    "                if(left == 1):\n",
    "                    bound_bottom_right = (x2-LANE_WIDTH,y2)\n",
    "                else:\n",
    "                    bound_bottom_right = (x2+LANE_WIDTH,y2)\n",
    "        i=i+1\n",
    "        \n",
    "    #drawing the top and bottom boundaries\n",
    "    cv2.line(bird_view,bound_bottom_left,bound_bottom_right,red,5)\n",
    "    cv2.line(bird_view,bound_top_left,bound_top_right,red,5)\n",
    "    \n",
    "    # drawing the green region representing the lane\n",
    "    contours = np.array([bound_top_left,bound_top_right,bound_bottom_right, bound_bottom_left])\n",
    "    cv2.fillPoly(bird_view,pts = [contours],color = green)\n",
    "\n",
    "    #transforming the view back from bird eye view\n",
    "    re_gen = warpPerspective(bird_view, mat_inv, size)\n",
    "\n",
    "    #combning modified frame with original frame\n",
    "    image = np.zeros_like(frame)\n",
    "    cv2.addWeighted(frame, 0.5, re_gen, 0.5,0, image)\n",
    "    pipeline.append(image)\n",
    "    if debug == 1:\n",
    "        return debug_mode(pipeline , resize_factor= 3)\n",
    "    else:\n",
    "        return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a9ec811a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#defining points for perspective transform\n",
    "input_top_left = [580,480]\n",
    "input_top_right = [820,480]\n",
    "input_bottom_right = [1200,700]\n",
    "input_bottom_left = [200,700]\n",
    "src_points = np.float32([input_bottom_left,input_top_left,input_top_right,input_bottom_right])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "93206759",
   "metadata": {},
   "outputs": [],
   "source": [
    "count = 0\n",
    "while cap.isOpened():\n",
    "    ret,frame = cap.read()\n",
    "    if not ret:\n",
    "        continue\n",
    "    #code for modifying video frames\n",
    "    dst_points = np.float32([[frame.shape[1] // 3,720],[frame.shape[1] // 3,0],[2 *( frame.shape[1] // 3),0],[2 * (frame.shape[1] // 3),720]])\n",
    "    frame = detectLane(frame, src_points, dst_points, (1280,720),kernel_op_size=2 , kernel_cl_size=7 , debug=1 )\n",
    "    cv2.imshow('window-name', frame)\n",
    "    \n",
    "    count = count + 1\n",
    "    if cv2.waitKey(10) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da4c7167",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
